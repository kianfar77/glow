.. _variantnormalization:

=====================
Variant Normalization
=====================

.. invisible-code-block: python

    import glow
    glow.register(spark)

    test_dir = 'test-data/variantsplitternormalizer-test/'
    df_original = spark.read.format('vcf').load(test_dir + 'test_left_align_hg38_altered.vcf')
    ref_genome_path = test_dir + 'Homo_sapiens_assembly38.20.21_altered.fasta'

Different genomic analysis tools often represent the same genomic variant in different ways, making it non-trivial to integrate and compare variants across call sets. Therefore, **variant normalization** is an essential step on variants before further downstream analysis to make sure the same variant is represented identically in different call sets. Normalization is achieved by making sure the variant is parsimonious and left-aligned (see `Variant Normalization <https://genome.sph.umich.edu/wiki/Variant_Normalization>`_ for more details).

Glow provides variant normalization capabilities as a DataFrame transformer as well as a sql expression function.

.. note::

  Glow'a variant normalization algorithm follows the same logic as those used in normalizations tools such as `bcftools norm <https://www.htslib.org/doc/bcftools.html#norm>`_ and `vt normalize <https://genome.sph.umich.edu/wiki/Vt#Normalization>`_. This normalization logic is different from the one used by GATK's `LeftAlignAndTrimVariants <https://gatk.broadinstitute.org/hc/en-us/articles/360037225872-LeftAlignAndTrimVariants>`_, which sometimes yields incorrect normalization (see `Variant Normalization <https://genome.sph.umich.edu/wiki/Variant_Normalization>`_ for more details).

``normalize_variants`` Transformer
==================================

``normalize_variants`` transformer to be applied on a variant DataFrame to normalize its variants, bringing unprecedented scalability to this operation. When applied on an input DataFrame of variants (e.g., generated by loading VCF or BGEN files), this transformer generates a DataFrame containing normalized variants. The ``replace_columns`` option can be used to control the output of the transformer as explained below.


Usage
=====

Assuming ``df_original`` is a variable of type DataFrame which contains the genomic variant records, and ``ref_genome_path`` is a variable of type String containing the path to the reference genome file, a minimal example of using this transformer for normalization is:

.. tabs::

    .. tab:: Python

        .. code-block:: python

            df_normalized = glow.transform("normalize_variants", df_original, reference_genome_path=ref_genome_path)

        .. invisible-code-block: python

            from pyspark.sql import Row

            expected_normalized_variant = Row(contigName='chr20', start=268, end=269, names=[], referenceAllele='A', alternateAlleles=['ATTTGAGATCTTCCCTCTTTTCTAATATAAACACATAAAGCTCTGTTTCCTTCTAGGTAACTGG'], normalizationStatus=Row(changed=True, errorMessage=None), qual=30.0, filters=[], splitFromMultiAllelic=False, INFO_AN=4, INFO_AF=[1.0], INFO_AC=[1], genotypes=[Row(sampleId='CHMI_CHMI3_WGS2', alleleDepths=None, phased=False, calls=[1, 1]), Row(sampleId='CHMI_CHMI3_WGS3', alleleDepths=None, phased=False, calls=[1, 1])])
            assert_rows_equal(df_normalized.head(), expected_normalized_variant)

    .. tab:: Scala

        .. code-block:: scala

            df_normalized = Glow.transform("normalize_variants", df_original, Map("reference_genome_path" -> ref_genome_path))

Options
=======
The ``normalize_variants`` transformer has the following options:

.. list-table::
   :header-rows: 1

   * - Option
     - Type
     - Possible values and description
   * - ``reference_genome_path``
     - string
     - Path to the reference genome ``.fasta`` or ``.fa`` file (required for normalization)
   * - ``replace_columns``
     - boolean
     - |
       | ``False``: The transformer does not touch the original ``start``, ``end``, ``referenceAllele`` and ``alternateAlleles`` columns. Instead, a StructType columns called ``normalizationResult`` is added to the DataFrame which contains the normalized ``start``, ``end``, ``referenceAllele``, and ``alternateAlleles`` columns as well as the ``normalizationStatus`` StructType as the fifth field, which contains the following subfields:
       |        ``changed``: Indicates whether the variant data was changed as a result of normalization or not.
       |        ``errorMessage``: An error message in case the attempt at normalizing the row hit an error. In this case, the changed field will be set to false. If no errors occur this field will be null.In case of error, the first four fields in normalizationResult will be null.
       |
       | ``True`` (default): The original ``start``, ``end``, ``referenceAllele``, and ``alternateAlleles`` columns are replaced with the normalized values in case they have changed. Otherwise (in case of no change or an error), the original ``start``, ``end``, ``referenceAllele``, and ``alternateAlleles`` are not touched. A StructType ``normalizationStatus`` column is added to the DataFrame with the same subfields explained above.
   * - ``mode`` (deprecated)
     - string
     - |
       | ``normalize``: Only normalizes the variants (if user does not pass the option, ``normalize`` is assumed as default)
       | ``split_and_normalize``: Split multiallelic variants to biallelic variants and then normalize the variants. This usage is deprecated. Instead, use :ref:`split_multiallelics transformer<split_multiallelics>` followed by normalize_variants transformer.
       | ``split``: Only split the multiallelic variants to biallelic without normalizing. This usage is deprecated. Instead, use :ref:`split_multiallelics transformer<split_multiallelics>`.

``normalize_variant`` Function
==============================
The normalizer can also be used as a SQL expression function applied on proper DataFrame columns to get the ``normalizationResult`` column. See this function at :ref:`pyspark_functions` for details on how to use it in the Python API. The function can be similarly used in Scala API or as a SQL expression.

.. notebook:: .. etl/normalizevariants.html
  :title: Variant normalization notebook
